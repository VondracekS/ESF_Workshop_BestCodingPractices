{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCoHH3/FcOc/+5SiQatzKS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VondracekS/ESF_Workshop_BestCodingPractices/blob/main/best_coding_practices.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Best Coding Practices Workshop\n",
        "17.3.2023 @ ESF Muni"
      ],
      "metadata": {
        "id": "Nh27uBKuUyxX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Git + Shell"
      ],
      "metadata": {
        "id": "Nr5ITRjcVJiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Which directory are you in?\n",
        "2. List all files within the current directory\n",
        "3. Clone the git repository available under https://github.com/VondracekS/ESF_Workshop_BestCodingPractices\n",
        "4. Search the directory and find the data\n",
        "5. Unzip the data\n",
        "\n",
        "Hints: \n",
        "- the needed commands are: *git clone, ls, cd, pwd, rm* (random order)\n",
        "- shell commands must begin with the \"!\", however to use cd, you need %cd"
      ],
      "metadata": {
        "id": "1bThiOYKVbAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: show the current directory\n",
        "!pwd"
      ],
      "metadata": {
        "id": "miVjHalyQ5Ao",
        "outputId": "26f2c5ea-b374-4961-ba09-d7426ace5283",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: list all folders/files within the directory\n",
        "!ls"
      ],
      "metadata": {
        "id": "7T7TEVckQ8WK",
        "outputId": "dcc4ec5b-309b-4b9b-8114-03ed32112f47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: clone the git repository\n",
        "!git clone https://github.com/VondracekS/ESF_Workshop_BestCodingPractices; ls"
      ],
      "metadata": {
        "id": "n9GWgno7RSw0",
        "outputId": "184408a4-0797-46c0-cefb-48f8ae2bc4ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ESF_Workshop_BestCodingPractices'...\n",
            "remote: Enumerating objects: 421, done.\u001b[K\n",
            "remote: Counting objects: 100% (421/421), done.\u001b[K\n",
            "remote: Compressing objects: 100% (401/401), done.\u001b[K\n",
            "remote: Total 421 (delta 24), reused 395 (delta 8), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (421/421), 7.46 MiB | 15.33 MiB/s, done.\n",
            "Resolving deltas: 100% (24/24), done.\n",
            "ESF_Workshop_BestCodingPractices  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the directory to the newly cloned one\n",
        "%cd ESF_Workshop_BestCodingPractices/"
      ],
      "metadata": {
        "id": "hXZOhonJRYsA",
        "outputId": "f75d9cee-01f1-40e4-ff4e-2ecd53ba82a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ESF_Workshop_BestCodingPractices\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2yXDSjlVVGF",
        "outputId": "a041862f-347c-4848-cbc3-581f9e7df028"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BCP_Workshop.pptx\t\t     data\n",
            "BestCodingPracices.nb.html\t     ESF_Workshop_BestCodingPractices.Rproj\n",
            "BestCodingPracices.Rmd\t\t     README.md\n",
            "best_coding_practices.ipynb\t     utils\n",
            "Copy_of_best_coding_practices.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lo5uYA7kVNyY",
        "outputId": "834e203e-2753-443c-8d78-c2c09f2347f5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ESF_Workshop_BestCodingPractices/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "sJh93Ei8RqNg",
        "outputId": "1265b759-75a3-4ef0-a1fa-5e36cf7a5af4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mspecdata\u001b[0m/  specdata.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip the data\n",
        "! unzip specdata.zip"
      ],
      "metadata": {
        "id": "kmiRf_dMRrgy",
        "outputId": "8dfec7c6-dd00-4762-d55a-ebb35c5c03f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  specdata.zip\n",
            "replace specdata/001.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: specdata/001.csv        \n",
            "  inflating: specdata/002.csv        \n",
            "  inflating: specdata/003.csv        \n",
            "  inflating: specdata/004.csv        \n",
            "  inflating: specdata/005.csv        \n",
            "  inflating: specdata/006.csv        \n",
            "  inflating: specdata/007.csv        \n",
            "  inflating: specdata/008.csv        \n",
            "  inflating: specdata/009.csv        \n",
            "  inflating: specdata/010.csv        \n",
            "  inflating: specdata/011.csv        \n",
            "  inflating: specdata/012.csv        \n",
            "  inflating: specdata/013.csv        \n",
            "  inflating: specdata/014.csv        \n",
            "  inflating: specdata/015.csv        \n",
            "  inflating: specdata/016.csv        \n",
            "  inflating: specdata/017.csv        \n",
            "  inflating: specdata/018.csv        \n",
            "  inflating: specdata/019.csv        \n",
            "  inflating: specdata/020.csv        \n",
            "  inflating: specdata/021.csv        \n",
            "  inflating: specdata/022.csv        \n",
            "  inflating: specdata/023.csv        \n",
            "  inflating: specdata/024.csv        \n",
            "  inflating: specdata/025.csv        \n",
            "  inflating: specdata/026.csv        \n",
            "  inflating: specdata/027.csv        \n",
            "  inflating: specdata/028.csv        \n",
            "  inflating: specdata/029.csv        \n",
            "  inflating: specdata/030.csv        \n",
            "  inflating: specdata/031.csv        \n",
            "  inflating: specdata/032.csv        \n",
            "  inflating: specdata/033.csv        \n",
            "  inflating: specdata/034.csv        \n",
            "  inflating: specdata/035.csv        \n",
            "  inflating: specdata/036.csv        \n",
            "  inflating: specdata/037.csv        \n",
            "  inflating: specdata/038.csv        \n",
            "  inflating: specdata/039.csv        \n",
            "  inflating: specdata/040.csv        \n",
            "  inflating: specdata/041.csv        \n",
            "  inflating: specdata/042.csv        \n",
            "  inflating: specdata/043.csv        \n",
            "  inflating: specdata/044.csv        \n",
            "  inflating: specdata/045.csv        \n",
            "  inflating: specdata/046.csv        \n",
            "  inflating: specdata/047.csv        \n",
            "  inflating: specdata/048.csv        \n",
            "  inflating: specdata/049.csv        \n",
            "  inflating: specdata/050.csv        \n",
            "  inflating: specdata/051.csv        \n",
            "  inflating: specdata/052.csv        \n",
            "  inflating: specdata/053.csv        \n",
            "  inflating: specdata/054.csv        \n",
            "  inflating: specdata/055.csv        \n",
            "  inflating: specdata/056.csv        \n",
            "  inflating: specdata/057.csv        \n",
            "  inflating: specdata/058.csv        \n",
            "  inflating: specdata/059.csv        \n",
            "  inflating: specdata/060.csv        \n",
            "  inflating: specdata/061.csv        \n",
            "  inflating: specdata/062.csv        \n",
            "  inflating: specdata/063.csv        \n",
            "  inflating: specdata/064.csv        \n",
            "  inflating: specdata/065.csv        \n",
            "  inflating: specdata/066.csv        \n",
            "  inflating: specdata/067.csv        \n",
            "  inflating: specdata/068.csv        \n",
            "  inflating: specdata/069.csv        \n",
            "  inflating: specdata/070.csv        \n",
            "  inflating: specdata/071.csv        \n",
            "  inflating: specdata/072.csv        \n",
            "  inflating: specdata/073.csv        \n",
            "  inflating: specdata/074.csv        \n",
            "  inflating: specdata/075.csv        \n",
            "  inflating: specdata/076.csv        \n",
            "  inflating: specdata/077.csv        \n",
            "  inflating: specdata/078.csv        \n",
            "  inflating: specdata/079.csv        \n",
            "  inflating: specdata/080.csv        \n",
            "  inflating: specdata/081.csv        \n",
            "  inflating: specdata/082.csv        \n",
            "  inflating: specdata/083.csv        \n",
            "  inflating: specdata/084.csv        \n",
            "  inflating: specdata/085.csv        \n",
            "  inflating: specdata/086.csv        \n",
            "  inflating: specdata/087.csv        \n",
            "  inflating: specdata/088.csv        \n",
            "  inflating: specdata/089.csv        \n",
            "  inflating: specdata/090.csv        \n",
            "  inflating: specdata/091.csv        \n",
            "  inflating: specdata/092.csv        \n",
            "  inflating: specdata/093.csv        \n",
            "  inflating: specdata/094.csv        \n",
            "  inflating: specdata/095.csv        \n",
            "  inflating: specdata/096.csv        \n",
            "  inflating: specdata/097.csv        \n",
            "  inflating: specdata/098.csv        \n",
            "  inflating: specdata/099.csv        \n",
            "  inflating: specdata/100.csv        \n",
            "  inflating: specdata/101.csv        \n",
            "  inflating: specdata/102.csv        \n",
            "  inflating: specdata/103.csv        \n",
            "  inflating: specdata/104.csv        \n",
            "  inflating: specdata/105.csv        \n",
            "  inflating: specdata/106.csv        \n",
            "  inflating: specdata/107.csv        \n",
            "  inflating: specdata/108.csv        \n",
            "  inflating: specdata/109.csv        \n",
            "  inflating: specdata/110.csv        \n",
            "  inflating: specdata/111.csv        \n",
            "  inflating: specdata/112.csv        \n",
            "  inflating: specdata/113.csv        \n",
            "  inflating: specdata/114.csv        \n",
            "  inflating: specdata/115.csv        \n",
            "  inflating: specdata/116.csv        \n",
            "  inflating: specdata/117.csv        \n",
            "  inflating: specdata/118.csv        \n",
            "  inflating: specdata/119.csv        \n",
            "  inflating: specdata/120.csv        \n",
            "  inflating: specdata/121.csv        \n",
            "  inflating: specdata/122.csv        \n",
            "  inflating: specdata/123.csv        \n",
            "  inflating: specdata/124.csv        \n",
            "  inflating: specdata/125.csv        \n",
            "  inflating: specdata/126.csv        \n",
            "  inflating: specdata/127.csv        \n",
            "  inflating: specdata/128.csv        \n",
            "  inflating: specdata/129.csv        \n",
            "  inflating: specdata/130.csv        \n",
            "  inflating: specdata/131.csv        \n",
            "  inflating: specdata/132.csv        \n",
            "  inflating: specdata/133.csv        \n",
            "  inflating: specdata/134.csv        \n",
            "  inflating: specdata/135.csv        \n",
            "  inflating: specdata/136.csv        \n",
            "  inflating: specdata/137.csv        \n",
            "  inflating: specdata/138.csv        \n",
            "  inflating: specdata/139.csv        \n",
            "  inflating: specdata/140.csv        \n",
            "  inflating: specdata/141.csv        \n",
            "  inflating: specdata/142.csv        \n",
            "  inflating: specdata/143.csv        \n",
            "  inflating: specdata/144.csv        \n",
            "  inflating: specdata/145.csv        \n",
            "  inflating: specdata/146.csv        \n",
            "  inflating: specdata/147.csv        \n",
            "  inflating: specdata/148.csv        \n",
            "  inflating: specdata/149.csv        \n",
            "  inflating: specdata/150.csv        \n",
            "  inflating: specdata/151.csv        \n",
            "  inflating: specdata/152.csv        \n",
            "  inflating: specdata/153.csv        \n",
            "  inflating: specdata/154.csv        \n",
            "  inflating: specdata/155.csv        \n",
            "  inflating: specdata/156.csv        \n",
            "  inflating: specdata/157.csv        \n",
            "  inflating: specdata/158.csv        \n",
            "  inflating: specdata/159.csv        \n",
            "  inflating: specdata/160.csv        \n",
            "  inflating: specdata/161.csv        \n",
            "  inflating: specdata/162.csv        \n",
            "  inflating: specdata/163.csv        \n",
            "  inflating: specdata/164.csv        \n",
            "  inflating: specdata/165.csv        \n",
            "  inflating: specdata/166.csv        \n",
            "  inflating: specdata/167.csv        \n",
            "  inflating: specdata/168.csv        \n",
            "  inflating: specdata/169.csv        \n",
            "  inflating: specdata/170.csv        \n",
            "  inflating: specdata/171.csv        \n",
            "  inflating: specdata/172.csv        \n",
            "  inflating: specdata/173.csv        \n",
            "  inflating: specdata/174.csv        \n",
            "  inflating: specdata/175.csv        \n",
            "  inflating: specdata/176.csv        \n",
            "  inflating: specdata/177.csv        \n",
            "  inflating: specdata/178.csv        \n",
            "  inflating: specdata/179.csv        \n",
            "  inflating: specdata/180.csv        \n",
            "  inflating: specdata/181.csv        \n",
            "  inflating: specdata/182.csv        \n",
            "  inflating: specdata/183.csv        \n",
            "  inflating: specdata/184.csv        \n",
            "  inflating: specdata/185.csv        \n",
            "  inflating: specdata/186.csv        \n",
            "  inflating: specdata/187.csv        \n",
            "  inflating: specdata/188.csv        \n",
            "  inflating: specdata/189.csv        \n",
            "  inflating: specdata/190.csv        \n",
            "  inflating: specdata/191.csv        \n",
            "  inflating: specdata/192.csv        \n",
            "  inflating: specdata/193.csv        \n",
            "  inflating: specdata/194.csv        \n",
            "  inflating: specdata/195.csv        \n",
            "  inflating: specdata/196.csv        \n",
            "  inflating: specdata/197.csv        \n",
            "  inflating: specdata/198.csv        \n",
            "  inflating: specdata/199.csv        \n",
            "  inflating: specdata/200.csv        \n",
            "  inflating: specdata/201.csv        \n",
            "  inflating: specdata/202.csv        \n",
            "  inflating: specdata/203.csv        \n",
            "  inflating: specdata/204.csv        \n",
            "  inflating: specdata/205.csv        \n",
            "  inflating: specdata/206.csv        \n",
            "  inflating: specdata/207.csv        \n",
            "  inflating: specdata/208.csv        \n",
            "  inflating: specdata/209.csv        \n",
            "  inflating: specdata/210.csv        \n",
            "  inflating: specdata/211.csv        \n",
            "  inflating: specdata/212.csv        \n",
            "  inflating: specdata/213.csv        \n",
            "  inflating: specdata/214.csv        \n",
            "  inflating: specdata/215.csv        \n",
            "  inflating: specdata/216.csv        \n",
            "  inflating: specdata/217.csv        \n",
            "  inflating: specdata/218.csv        \n",
            "  inflating: specdata/219.csv        \n",
            "  inflating: specdata/220.csv        \n",
            "  inflating: specdata/221.csv        \n",
            "  inflating: specdata/222.csv        \n",
            "  inflating: specdata/223.csv        \n",
            "  inflating: specdata/224.csv        \n",
            "  inflating: specdata/225.csv        \n",
            "  inflating: specdata/226.csv        \n",
            "  inflating: specdata/227.csv        \n",
            "  inflating: specdata/228.csv        \n",
            "  inflating: specdata/229.csv        \n",
            "  inflating: specdata/230.csv        \n",
            "  inflating: specdata/231.csv        \n",
            "  inflating: specdata/232.csv        \n",
            "  inflating: specdata/233.csv        \n",
            "  inflating: specdata/234.csv        \n",
            "  inflating: specdata/235.csv        \n",
            "  inflating: specdata/236.csv        \n",
            "  inflating: specdata/237.csv        \n",
            "  inflating: specdata/238.csv        \n",
            "  inflating: specdata/239.csv        \n",
            "  inflating: specdata/240.csv        \n",
            "  inflating: specdata/241.csv        \n",
            "  inflating: specdata/242.csv        \n",
            "  inflating: specdata/243.csv        \n",
            "  inflating: specdata/244.csv        \n",
            "  inflating: specdata/245.csv        \n",
            "  inflating: specdata/246.csv        \n",
            "  inflating: specdata/247.csv        \n",
            "  inflating: specdata/248.csv        \n",
            "  inflating: specdata/249.csv        \n",
            "  inflating: specdata/250.csv        \n",
            "  inflating: specdata/251.csv        \n",
            "  inflating: specdata/252.csv        \n",
            "  inflating: specdata/253.csv        \n",
            "  inflating: specdata/254.csv        \n",
            "  inflating: specdata/255.csv        \n",
            "  inflating: specdata/256.csv        \n",
            "  inflating: specdata/257.csv        \n",
            "  inflating: specdata/258.csv        \n",
            "  inflating: specdata/259.csv        \n",
            "  inflating: specdata/260.csv        \n",
            "  inflating: specdata/261.csv        \n",
            "  inflating: specdata/262.csv        \n",
            "  inflating: specdata/263.csv        \n",
            "  inflating: specdata/264.csv        \n",
            "  inflating: specdata/265.csv        \n",
            "  inflating: specdata/266.csv        \n",
            "  inflating: specdata/267.csv        \n",
            "  inflating: specdata/268.csv        \n",
            "  inflating: specdata/269.csv        \n",
            "  inflating: specdata/270.csv        \n",
            "  inflating: specdata/271.csv        \n",
            "  inflating: specdata/272.csv        \n",
            "  inflating: specdata/273.csv        \n",
            "  inflating: specdata/274.csv        \n",
            "  inflating: specdata/275.csv        \n",
            "  inflating: specdata/276.csv        \n",
            "  inflating: specdata/277.csv        \n",
            "  inflating: specdata/278.csv        \n",
            "  inflating: specdata/279.csv        \n",
            "  inflating: specdata/280.csv        \n",
            "  inflating: specdata/281.csv        \n",
            "  inflating: specdata/282.csv        \n",
            "  inflating: specdata/283.csv        \n",
            "  inflating: specdata/284.csv        \n",
            "  inflating: specdata/285.csv        \n",
            "  inflating: specdata/286.csv        \n",
            "  inflating: specdata/287.csv        \n",
            "  inflating: specdata/288.csv        \n",
            "  inflating: specdata/289.csv        \n",
            "  inflating: specdata/290.csv        \n",
            "  inflating: specdata/291.csv        \n",
            "  inflating: specdata/292.csv        \n",
            "  inflating: specdata/293.csv        \n",
            "  inflating: specdata/294.csv        \n",
            "  inflating: specdata/295.csv        \n",
            "  inflating: specdata/296.csv        \n",
            "  inflating: specdata/297.csv        \n",
            "  inflating: specdata/298.csv        \n",
            "  inflating: specdata/299.csv        \n",
            "  inflating: specdata/300.csv        \n",
            "  inflating: specdata/301.csv        \n",
            "  inflating: specdata/302.csv        \n",
            "  inflating: specdata/303.csv        \n",
            "  inflating: specdata/304.csv        \n",
            "  inflating: specdata/305.csv        \n",
            "  inflating: specdata/306.csv        \n",
            "  inflating: specdata/307.csv        \n",
            "  inflating: specdata/308.csv        \n",
            "  inflating: specdata/309.csv        \n",
            "  inflating: specdata/310.csv        \n",
            "  inflating: specdata/311.csv        \n",
            "  inflating: specdata/312.csv        \n",
            "  inflating: specdata/313.csv        \n",
            "  inflating: specdata/314.csv        \n",
            "  inflating: specdata/315.csv        \n",
            "  inflating: specdata/316.csv        \n",
            "  inflating: specdata/317.csv        \n",
            "  inflating: specdata/318.csv        \n",
            "  inflating: specdata/319.csv        \n",
            "  inflating: specdata/320.csv        \n",
            "  inflating: specdata/320.xlsx       \n",
            "  inflating: specdata/321.csv        \n",
            "  inflating: specdata/322.csv        \n",
            "  inflating: specdata/323.csv        \n",
            "  inflating: specdata/324.csv        \n",
            "  inflating: specdata/325.csv        \n",
            "  inflating: specdata/326.csv        \n",
            "  inflating: specdata/327.csv        \n",
            "  inflating: specdata/328.csv        \n",
            "  inflating: specdata/329.csv        \n",
            "  inflating: specdata/330.csv        \n",
            "  inflating: specdata/331.csv        \n",
            "  inflating: specdata/332.csv        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# force removal of the original zip file\n",
        "!rm -rf specdata.zip"
      ],
      "metadata": {
        "id": "6u3S-mGeRv6z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Python\n",
        "\n",
        "Now it's time for some programming. Whwnever you feel completely lost, feel free to use the functions defined in the *help* module which is imported in\n",
        "the cell below. You can view the source code by clicking on the help module in files as well."
      ],
      "metadata": {
        "id": "SQzBWZj8SPZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append('../data/utils/')"
      ],
      "metadata": {
        "id": "L8mIaDVejktB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import help\n",
        "help.read_csv"
      ],
      "metadata": {
        "id": "Z23wm_opkBdR",
        "outputId": "1d4a442a-4e2c-4d02-eba8-104779fb4df3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function utils.help.read_csv(path: str) -> dict>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, you will be complete te following tasks:\n",
        "- iteratively searching throgh a directory and subsequently loading data using os package\n",
        "- testing of the loaded data\n",
        "- using a modular design, you will separate functionalities into operation-specific functions\n"
      ],
      "metadata": {
        "id": "2QMe-qLdS5NW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Create a function that:\n",
        "# - loads all the .csv files from the directory \n",
        "# - stores them in a dictionary;\n",
        "# - add some explanatory docstring\n",
        "#\n",
        "# hints: os.listdir, string.split, make sure you read only csv files, \n",
        "# btw: is the function name the best possible one? change this eventually\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def read_csv(path: str) -> dict:\n",
        "  \"\"\"\n",
        "  Some docstring would be nice, eh?\n",
        "  \"\"\"\n",
        "  csv_dict = {}\n",
        "  pass"
      ],
      "metadata": {
        "id": "AEKuWMPpooUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: call the exact previously defined function (you might have changed \n",
        "# the name) if you have changed it\n",
        "\n",
        "def test_read_csv(path):\n",
        "  dict_full = read_csv(path)\n",
        "  assert len(dict_full) == len([f for f in os.listdir(path) if \".csv\" in f])\n",
        "  print(f\"Tests passed for the test_read_csv({path})\")\n",
        "\n",
        "test_read_csv(\"./specdata/\")"
      ],
      "metadata": {
        "id": "xVZKROPFzErp",
        "outputId": "2d9e9070-0d78-4dc8-e580-57ed577fef21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tests passed for the test_read_csv(./specdata/)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "OK, now you have the function. However, some improvements are still possible.\n",
        "PLease finish the following tasks:\n",
        "\n",
        "- adjust the fuction to ignore the \"0\" padding for all numbers smaller than 100 (e.g. \"050\" will be replaced by \"50\" and so on) -> read_csv_v2()\n",
        "- separate the padding removal to another function -> remove_padding()\n",
        "- write a test for the padding removal\n",
        "- use the remove_padding() function within the read_csv_v3\n",
        "- extend the function to be able to specify only particular .csv files to be read (and if not specified, just load all) -> read_csv_v4()\n",
        "\n",
        "Again, please find more suitable names for all the variables"
      ],
      "metadata": {
        "id": "Kc9Ljm7mqhYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: ignore the padding within the function\n",
        "# hint: did you know that \"011\" integer will be read as \"11\"?\n",
        "\n",
        "def read_csv_v2(path: str) -> dict:\n",
        "  csv_dict = {}\n",
        "  pass"
      ],
      "metadata": {
        "id": "MsqkqAWjvPuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: separating the padding removal function\n",
        "def remove_padding(tgt_string: str) -> str:\n",
        "  pass"
      ],
      "metadata": {
        "id": "aKSLtjTqrsSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: write the test (e.g. for cases where should and should not be the \n",
        "# 0-padding removed)\n",
        "def test_remove_padding(test_cases=[]) -> None:\n",
        "  assert remove_padding(test_cases) == None\n",
        "test_remove_padding()"
      ],
      "metadata": {
        "id": "ymXNZs55sF3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: adjust the former function so that you use the padding removal\n",
        "def read_csv_v3(path: str) -> dict:\n",
        "  pass"
      ],
      "metadata": {
        "id": "9bNvg0qLwXIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the last part, create a new function, called get_monitor()\n",
        "This function will do the following:\n",
        "- load the specific monitoring stations\n",
        "- concatenate all data frames from the dictionary\n",
        "- if dropna, the function will drop all na values for all loaded tables\n",
        "- if print_stats, the function will print descriptive stats for all the data frames\n",
        "- if plot, the function will plot all variables in a single plot (\n",
        "  i.e. Date will be on the x axis, concentration on the y axis, ID will be in the plot title"
      ],
      "metadata": {
        "id": "N3BKXwwK8-8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: get_monitor function\n",
        "# Hints: \n",
        "# -separate functionalities (loading the data and plotting the data)\n",
        "# -use already defined function that loads the csv data\n",
        "\n",
        "def get_monitor(station_ids: list, dropna: bool=True, plot=False) -> pd.DataFrame:\n",
        "  \"\"\"\n",
        "  :param station_ids: list of integers defining the specific station_id\n",
        "  :param dropna: bool determiing whether to include NAs in the output df\n",
        "  :param plot: determines whether to plot the concatenated data frame\n",
        "  :return: dataframe of concatenated specific stations\n",
        "  \"\"\"\n",
        "  pass"
      ],
      "metadata": {
        "id": "PVzdKVMKWVqv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}